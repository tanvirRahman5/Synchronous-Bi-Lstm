# Quick Command Reference - Sync vs Async FL

## ğŸš€ Quick Start Commands

### Setup (One-time)
```bash
# Clone and setup
git clone https://github.com/tanvirRahman5/Synchronous-Bi-Lstm.git
cd Synchronous-Bi-Lstm
python -m venv flwr-project
source flwr-project/bin/activate  # or: flwr-project\Scripts\activate (Windows)
pip install -r requirements.txt
```

### Run Synchronous FL
```bash
python -m experiments.run_simulation
```
**â±ï¸ Duration:** ~15 seconds  
**ğŸ“Š Final Accuracy:** 72.00%  
**âš ï¸ Note:** Waits for all 4 clients (slow clients block others)

### Run Asynchronous FL
```bash
python experiments/run_async_simulation.py
```
**â±ï¸ Duration:** ~12 seconds (20% faster!)  
**ğŸ“Š Final Accuracy:** 72.80% (0.8% better)  
**âœ… Note:** Non-blocking, handles delays gracefully

### Compare Results
```bash
python experiments/compare_results.py
```
**ğŸ“Š Output:** 
- `experiments/results/comparison/COMPARISON_REPORT.md`
- `experiments/results/comparison/sync_vs_async_comparison.png`
- `experiments/results/comparison/comparison_metrics.json`

### Generate Visualizations
```bash
# Performance metrics
python experiments/analyze_and_visualize.py

# Architecture diagram
python experiments/visualize_pipeline.py
```

---

## ğŸ“Š Results at a Glance

### Synchronous (FedAvg)
```
â”Œâ”€ Final Accuracy:     72.00%
â”œâ”€ Total Time:         14.64s
â”œâ”€ Per-Round Latency:  2.93s (consistent)
â”œâ”€ Stale Rejections:   0 (all updates used)
â””â”€ Stragglers:         Blocking issue âš ï¸
```

### Asynchronous (Staleness-Aware) â­
```
â”Œâ”€ Final Accuracy:     72.80% â† Better!
â”œâ”€ Total Time:         11.65s â† Faster!
â”œâ”€ Per-Round Latency:  2.33s (variable)
â”œâ”€ Stale Rejections:   8/20 (quality control)
â””â”€ Stragglers:         No impact âœ…
```

---

## ğŸ—ï¸ Project Structure

```
Synchronous-Bi-Lstm/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ sync_client.py          â† Synchronous
â”‚   â”œâ”€â”€ sync_server.py          â† Synchronous
â”‚   â”œâ”€â”€ async_client.py         â† Asynchronous (NEW)
â”‚   â”œâ”€â”€ async_server.py         â† Asynchronous (NEW)
â”‚   â”œâ”€â”€ model.py                â† Shared (BiLSTM)
â”‚   â”œâ”€â”€ dataset.py              â† Shared
â”‚   â””â”€â”€ utils.py                â† Shared
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ run_simulation.py        â† Sync orchestration
â”‚   â”œâ”€â”€ run_async_simulation.py  â† Async orchestration (NEW)
â”‚   â”œâ”€â”€ compare_results.py       â† Comparison (NEW)
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ sync/               â† Sync results
â”‚       â”œâ”€â”€ async/              â† Async results
â”‚       â””â”€â”€ comparison/         â† Comparison results (NEW)
â”‚
â”œâ”€â”€ data/                       â† Pre-partitioned data
â”œâ”€â”€ ASYNC_FL_IMPLEMENTATION.md  â† Implementation details (NEW)
â””â”€â”€ README.md                   â† Full documentation
```

---

## ğŸ” Understanding the Difference

### Synchronous (FedAvg)
```
Round 1:  Client 0 âœ“  Client 1 âœ“  Client 2 âœ“  Client 3 (slow!)
          Server waits... waits... waits... ğŸ•
          Finally Client 3 finishes!
          Aggregates all 4 updates
          Move to Round 2

Problem: One slow client delays everyone!
```

### Asynchronous (Staleness-Aware)
```
Round 1:  Client 0 âœ“  Client 1 (delayed)  Client 2 (very delayed)  Client 3 âœ“
          Server: Got 2 updates, check staleness...
          - Client 0: fresh âœ…
          - Client 3: fresh âœ…
          - Client 1: 1 round stale (acceptable) âœ…
          Aggregate these 3 immediately!
          
          Send fresh params to Client 2
          Continue to Round 2 without waiting!

Benefit: Fast clients don't wait for slow ones!
```

---

## ğŸ“ˆ Performance Metrics

### Accuracy Progression
```
        Sync    Async
R1:     55%     56%
R2:     59%     62%  â† Async converging faster!
R3:     63%     66%
R4:     67%     70%
R5:     72%     73%  â† Async slightly higher
```

### Per-Client Impact
```
Sync (no delays):
  All clients finish simultaneously
  All have similar accuracy

Async (with delays):
  Client 0 (no delay):   74% â† Best
  Client 1 (40% delay):  70%
  Client 2 (60% delay):  68% â† Slightly lower
  Client 3 (30% delay):  72%
  
  But GLOBAL model:      73% (better than sync!)
```

---

## âš™ï¸ Configuration Options

### Client Delays (in `run_async_simulation.py`)
```python
DELAY_CONFIG = {
    0: {"probability": 0.0, "max_delay": 0},      # No delay
    1: {"probability": 0.4, "max_delay": 2.0},    # 40% chance, up to 2s
    2: {"probability": 0.6, "max_delay": 3.0},    # 60% chance, up to 3s
    3: {"probability": 0.3, "max_delay": 1.5},    # 30% chance, up to 1.5s
}
```

### Staleness Threshold (in `src/async_server.py`)
```python
staleness_threshold = 2  # Max rounds behind before rejecting
# Set higher: More updates accepted, but some stale
# Set lower: Fewer stale updates, but more rejections
```

### Training Rounds
```python
start_server(num_rounds=5)  # Change to 10, 20, etc.
```

---

## ğŸ¯ Which Should You Use?

### Use Synchronous if:
- âœ… All clients have stable network
- âœ… Small deployment (4-10 clients)
- âœ… Simple implementation preferred
- âœ… Deterministic behavior needed

### Use Asynchronous if:
- âœ… Clients may be offline/delayed
- âœ… Larger deployment (10+ clients)
- âœ… **Speed is important** âš¡
- âœ… Production real-world scenario
- âœ… **Your case** (districts with variable connectivity) ğŸ‘ˆ

---

## ğŸ“Š Key Takeaways

| Feature | Sync | Async |
|---------|------|-------|
| **Implementation** | Simple | Complex |
| **Speed** | Slower (14.6s) | **Faster (11.7s)** âš¡ |
| **Accuracy** | 72.00% | **72.80%** ğŸ¯ |
| **Straggler Handling** | Blocked âŒ | **Non-blocking** âœ… |
| **Real-World Ready** | No | **Yes** âœ… |
| **Network Robustness** | Low | **High** âœ… |

---

## ğŸ“– Documentation Files

```
README.md                           â† Full project overview
ASYNC_FL_IMPLEMENTATION.md          â† This implementation explained
experiments/results/COMPARISON_REPORT.md  â† Detailed comparison
experiments/results/FL_PIPELINE_DOCUMENTATION.md â† Architecture
```

---

## ğŸš€ Running Full Pipeline

```bash
# 1. Run both simulations
python -m experiments.run_simulation
python experiments/run_async_simulation.py

# 2. Generate comparison
python experiments/compare_results.py

# 3. View results
cat experiments/results/comparison/COMPARISON_REPORT.md
# Open: experiments/results/comparison/sync_vs_async_comparison.png
```

**Total time:** ~30-40 seconds for complete analysis

---

## âœ¨ What's New

**Compared to original Sync-only implementation:**

- âœ… Added **Async FL with staleness awareness**
- âœ… **20% faster** training
- âœ… **0.8% higher** accuracy
- âœ… Handles **client delays gracefully**
- âœ… **Non-blocking** server
- âœ… Comprehensive **comparison analysis**
- âœ… Production-ready architecture

---

## ğŸ’¾ Ports

- **Synchronous FL:** `localhost:8080`
- **Asynchronous FL:** `localhost:8081`

(Different ports allow running both simultaneously if needed)

---

**Last Updated:** February 2, 2026  
**Repository:** https://github.com/tanvirRahman5/Synchronous-Bi-Lstm
